<!DOCTYPE html>
<html>
<head>
<title>README.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<!--ここから追記 1.(数式に対応させる)-->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax:{inlineMath: [['$', '$']]},
      messageStyle: "none"
    });
</script>
<!--追記 1.ここまで-->
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
    <!--ここから追記 2.(--- で改ページ)-->
    <style>  
      hr {  
        opacity: 0;  
        break-after: page;  
      }  
    </style>  
    <!--追記 2.ここまで-->
<h1 id="%E3%83%A2%E3%83%87%E3%83%AB%E9%81%B8%E6%8A%9E%E3%81%A8%E3%83%99%E3%82%A4%E3%82%BA%E7%B7%9A%E5%BD%A2%E8%AD%98%E5%88%A5">モデル選択とベイズ線形識別</h1>
<h2 id="%E3%83%A2%E3%83%87%E3%83%AB%E9%81%B8%E6%8A%9E">モデル選択</h2>
<p>前回の資料から識別問題を取り扱っているが、すでに述べたように、
識別問題をある関数の最小化もしくは最大化の問題にすることで、回帰で学んできた方法にほぼ沿った形でデータの訓練や予測を行うことができる。
識別問題では分類のための関数（活性化関数：ロジスティック回帰で使うシグモイド関数のこと）があるために、求めたい重み$\vec{w}$で陽に偏微分できない点が異なるが、
その点を別にすれば、この講義ではずっと同じようなことをしていることに気づき始めている人もいると思う。</p>
<p>さて、前回、事後分布最大化の際に導入した事前分布の項として損失関数に$L2$-ノルム（$\vec{w}^\top \vec{w}$の項のこと）を導入した。pythonの演習ではこれをC-パラメータを変更しながらその項による分類精度の影響を調べたしたが、このC-パラメータは超パラメータであり、これもやはり回帰で行ったように適切な値を別途求めなければならない。すなわち、モデル選択を行った（C-パラメータを決定した）上で、そのモデルの精度を別な独立のデータによって評価する必要がある。ここでも回帰との類似性が見て取れる。識別問題でも代表的な方法は２つ、データ分割による方法とベイズによる方法である。</p>
<h2 id="%E3%83%A2%E3%83%87%E3%83%AB%E9%81%B8%E6%8A%9E%E3%81%AE%E6%96%B9%E6%B3%951%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E5%89%B2">モデル選択の方法1:データ分割</h2>
<p>回帰で行ったことと概念はまったく同じであるが、１つだけ注意しておくことがある。
識別問題の場合、訓練データに分けたいグループorクラスの情報がある。
<strong>データを分割する際には、このクラスのデータ数の割合が元のデータに等しいように分類する</strong>（図7-1）。
このようにしておくことで、訓練や検証の場面で本来のデータと異なったクラスのデータ数の影響を誤って学習しないようにすることができる。</p>
<p>このようにデータを分割後、
超パラメータを変えて訓練データで学習された$\vec{w}$を持つモデルを多数用意した中で、検証データを最もよく再現する超パラメータを選択する（モデル選択する）。
テストデータは、モデル選択までの一連の作業では一切使わない。これは最終的に選択されたモデルの予測精度（or誤差）を評価する際に使用する。
図では訓練や検証でのデータ分割と同じ数に分割しているが、これは同じでなくても良い。</p>
<p>この図で示したのはk交差検証（k-fold cross validation）であるが、
LOO法（Leave-one-out method）やランダムにデータをサンプリングする
ブートストラップ法も当然可能である。</p>
<p>回帰の時に紹介した<strong>モデル平均</strong>は、識別問題では多数決で行うこともできる。
また、識別モデルがクラス割り当ての確率を与えるモデルである場合には、確率を平均してからクラス割り当ての判定を下すということもできる。</p>
<p><img src="images/7_1.png" width="500"><br>
<em>図7-1.
データ分割の例: 5-fold cross validationでは、訓練と検証を合わせたデータを５つのグループにわけ、そのうちの１つを検証、残りを訓練に使用する。
回帰との相違は、識別問題の場合はデータにクラスの情報が含まれている点である。それは訓練・検証・テストに基のデータと同じ比率になるように分割するのが望ましい。</em></p>
<h2 id="%E3%83%A2%E3%83%87%E3%83%AB%E9%81%B8%E6%8A%9E%E3%81%AE%E6%96%B9%E6%B3%952%E3%83%99%E3%82%A4%E3%82%BA%E3%81%AE%E3%82%A2%E3%83%97%E3%83%AD%E3%83%BC%E3%83%81">モデル選択の方法2:ベイズのアプローチ</h2>
<p>ベイズ線形回帰で行ったことは、まず$\vec{w}$の事後分布を求め、
新しいデータが得られた時その事後分布を重みづけして予測する（予測分布を求める）ということであった。
得られた結果はもはや$\vec{w}$の関数ではなく、超パラメータの関数となる。そのため、その結果が超パラメータに関して最大（損失関数の場合は最小）となる
値を、最適な超パラメータと考えた。これと同じことを識別でも行うことができる。ただし、回帰の時もそうであったが、予測分布を求める
ために必要な事後分布を重みづけした積分は解析的に実行することができない。
さらに困難なことに、線形識別モデルでは事後分布さえも解析的に表すことができない（回帰では事後分布はガウス分布だった）。
従って、ここでは近似方法の概略を述べるにとどめる。ベイズ線形識別モデルの概念だけ理解できれば良い。</p>
<p>まず、事後分布について。線形回帰モデルでは事後分布もガウス分布になったが、線形識別モデルでは事後分布も具体的な形を求めることが困難である。
$\vec{w}$の事前分布は、線形識別モデルでもガウス分布を採用しているので、事後分布のガウス分布に近似することを考える。
最も単純な近似は、事後分布を最大にする$\vec{w}_{MAP}$（MAPはMaximum a Posteriorのこと）をその平均、
最小化したい関数の２階微分を分散（$\vec{w}$が多変数の場合は共分散）$S_N$として、</p>
<p>$$
q(\vec{w}) = {\cal N}(\vec{w}|\vec{w}_{MAP}, S_N)
\hspace{2mm}\cdots(1)
$$</p>
<p>とすることであり、この近似をラプラス近似と呼ぶ。</p>
<p><strong>練習１：</strong>
関数$f(x)$をラプラス近似せよ。また、具体的に$f(x) = -\frac{1}{2}(x-2)^2+1$の場合、
ラプラス近似するとどのような分布になるか？
<br>
<br>
<br>
<br></p>
<p>$\vec{w}_{MAP}$に正則化項のパラメータ（前資料の式(7)の$\alpha$）が含まれており、
これが陽に示されない場合、次の予測確率を$\alpha$の関数として数値的に求めなければならなくなる。
式(1)を事後分布とした時、識別の予測確率、例えばクラス1($C_1$)の予測確率は、</p>
<p>$$
p(C_1|\vec{t}) = \int p(C_1|\vec{w}) q(\vec{w}|\vec{t}) d\vec{w}
\hspace{2mm}\cdots(2)
$$</p>
<p>となる。これは観測されたデータから構成される尤度関数$p(C_1|\vec{w})$に対し、$\vec{w}$の可能性を全て考慮に入れて$C_1$となる確率を求めるということをしている。
式(2)の右辺の積分は、$q(\vec{w}|\vec{t})$がガウス分布としても$p(C_1|\vec{w})$がシグモイド関数のため解析的に導くことができない。
そのため、さらに近似をして積分を陽に求める必要がある。</p>
<h2 id="python%E3%81%AB%E3%82%88%E3%82%8B%E3%83%A2%E3%83%87%E3%83%AB%E9%81%B8%E6%8A%9E">pythonによるモデル選択</h2>
<h3 id="%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E5%89%B2%E3%81%AB%E3%82%88%E3%82%8B%E6%96%B9%E6%B3%95">データ分割による方法</h3>
<h4 id="%E4%BB%8A%E5%9B%9E%E4%BD%BF%E3%81%86%E3%83%87%E3%83%BC%E3%82%BFiris-%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AE%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%81%BF">今回使うデータ：iris データの読み込み</h4>
<p>irisデータは、機械学習の解説における文脈で、具体的なデータの例として頻繁に使用されている有名なデータである。
セトナ(setosa)、バーシクル(versicolor)、 バージニカ(virginica)という3種類（種(Species)）のあやめ（iris）
を4個の計測値（がく片長(Sepal Length),がく片幅(Sepal Width),花びら長(Petal Length),
花びら幅(Petal Width)から分類するモデル作成の練習として良く用いられている。
データは150個存在している。これを図１に示すように
Train : Validation : Test = 6 : 2 : 2
に分割することを考えよう。</p>
<p><img src="images/7_2.png" width="500"><br>
<em>図7-2.データの分割</em></p>
<p>分割の方法は$<em>{150}C</em>{90}$ $\times$ $<em>{60}C</em>{30}$の
コンビネーションの数だけ存在する。
皆さんはどのように分割する？
ここではまず、乱数を使って分割する方法を行ってみたい。</p>
<p>例題１：iris_data.csvに格納されているデータを乱数
（pandasのsampleを使ってランダム抽出）を使って
Train : Validation : Test = 6 : 2 : 2の割合で分割せよ。
<br>
<br>
<br>
<br>
<br></p>
<p>（解答例）</p>
<pre class="hljs"><code><div>dataname = <span class="hljs-string">"iris_data.csv"</span>
df = pd.read_csv(dataname, encoding=<span class="hljs-string">"SHIFT-JIS"</span>)
num_data = len(df)
data_split = [<span class="hljs-number">0.6</span>,<span class="hljs-number">0.2</span>,<span class="hljs-number">0.2</span>]
<span class="hljs-comment"># ここまでデータの読み込みとデータ数、分割割合を記述</span>
num_train = np.int16(num_data * data_split[<span class="hljs-number">0</span>])
num_validation = np.int16(num_data * data_split[<span class="hljs-number">1</span>])
num_test = num_data - num_train - num_validation
df_train = df.sample(num_train)
df_drop = df.drop(index=df_train.index)
df_validation = df_drop.sample(num_validation)
df_test = df_drop.drop(index=df_validation.index)
</div></code></pre>
<p>このデータにはセトナ(setosa)、バーシクル(versicolor)、 バージニカ(virginica)が各々50個存在している。
上の手順ではこれらの種に関係なく150個のデータを6:2:2に分割した。
このように150個のデータをランダムにサンプリングするよりも、３種それぞれでTrain : Validation : Test = 30個 : 10個 : 10個
に分類する方が良い。
次にそのような分割を行なってみよう。</p>
<p>例題２：iris_data.csvに格納されているデータを
セトナ(setosa)、バーシクル(versicolor)、 バージニカ(virginica)の
３種それぞれのデータを乱数を使ってTrain : Validation : Test = 6 : 2 : 2の割合で分割せよ。
<br>
<br>
<br>
<br>
<br></p>
<p>基本的に例題１の解答例を使う。
例題１のdfをsetosa、versicolor、virginicaごとに分けて例題1をそれぞれで使うと良い。</p>
<h4 id="k-fold-cross-validation">k-fold cross validation</h4>
<p>データの分割方法の代表にk-fold cross validationがある。
これはデータをk個のグループに分割して交差検証を行う方法である
（図6-2）。
この場合、k個のグループの分割にはそれぞれのクループへの症例の
重複を避けるために乱数を使わずにforループなどで行うと良い。</p>
<p><img src="images/7_3.png" width="500"><br>
<em>図7-3.データの分割: k-fold cross validation</em></p>
<p>例題３：iris_data.csvに格納されているデータを、セトナ(setosa)、
バーシクル(versicolor)、 バージニカ(virginica)の３種
それぞれ図7-3のようにTrain : Validation : Test = 6 : 2 : 2の割合で
5-foldで分割するコードを作成せよ。
<br>
<br>
<br>
<br>
<br></p>
<h4 id="%E5%8F%82%E8%80%83%E3%83%87%E3%83%BC%E3%82%BF%E6%95%B0%E3%81%8C%E5%B0%91%E3%81%AA%E3%81%84%E5%A0%B4%E5%90%88">参考：データ数が少ない場合</h4>
<p>データ数が少ない場合、データ分割によって貴重なデータがさらに少ない
下で学習を行わなければならなくなる。
学習データが少ないと、良いパラメータ推定ができなくなる恐れがあり、
予測の精度も一般に落ちる。
したがって、なるべく多くのデータを使って学習を行うようにしたいと考えるならば、
k-fold cross validationの究極としてデータのうち１つのみをテストデータ
として用いるLeave-one-out (LOO)法の適用が思いつく。
また、validationデータで行っていたモデル選択を、
仮説とデータから自動的に決めるということも可能である。
ただ、何れにしてもデータ数が少ない場合はモデルの評価が不十分になりがちなので、
追加データを手に入れて評価を行うことが望まれる。</p>
<h2 id="%E6%BC%94%E7%BF%92%E3%83%AC%E3%83%9D%E3%83%BC%E3%83%88">演習レポート</h2>
<ul>
<li>(1) 例題2の方法で分割された訓練データ（train）を使ってロジスティック回帰モデルを学習し、
検証データ（validation）に対して最適なCパラメータを決定せよ。</li>
<li>(2) 上記で決まった最適なCパラメータをモデルをテストデータ（test）
に当てはめた時の結果を分割表で示せ。</li>
<li>(3) 上記結果を考察せよ。</li>
</ul>

</body>
</html>
